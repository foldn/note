1. 计算机网络

1. http1.0和http2.0的区别，优化点
	1. http网络连接，如何实现通信，如何保证通信顺序
	2. 为什么使用长连接，使用长连接的优点是什么，一次连接只能进行一个请求么，如果可以多个，通过什么实现，如何保证多个请求的返回体能够返回给对应的请求服务器
2. 操作系统还记得什么知识
3. 操作系统如何保证线程安全（同步机制）
	1. 高并发情况下通过cas或者读写锁更优
		1. cas原子操作：通过硬件原子操作实现
			1. cas原子操作的ABA问题：我们修改的前提是V和E相等，有可能我们进行修改的过程中，V的值已经发生过变化，然后又变化回来了（A-B-A）
			2. ABA问题的解决：通过对V新增一个版本号，根据版本号确定是否一致
		2. 互斥机制：通过互斥锁、自旋锁（临界区是同一个时间只允许一个线程访问的系统资源，必须使用同步机制保护，例如文件系统）
			1. 互斥锁（适用于临界区操作时间长）：同一时间只允许一个线程访问，其他线程访问，将其加到阻塞队列中，待当前线程执行完，开始执行阻塞队列头部线程
			2. 自旋锁（适用于临界区操作时间短，多cpu环境）：当前资源被一个线程访问时，其他线程请求访问，不会被阻塞，而是通过循环访问当前资源，查看是否已被上一个线程释放
		3. 内存屏障：通过内存屏障强制指定指令的执行顺序，由于多线程的环境，编译器可能会对指令进行重排序，因此通过内存屏障可以防止执行乱序执行
		4. 优先继承协议：高优先级进程被低优先级进程阻塞，暂时提升低优先级进程的优先级，使其快速执行完成释放资源，然后恢复锁
		5. 进程间通信：管道、消息队列、共享内存、信号量、套接字、信号等
			1. 管道：数据单向流动，从父节点流动到子节点或者子节点到父节点，两者间有一个通信通道
			2. 消息队列：消息队列间通过消息体内设置的标识符来进行通信
			3. 共享内存：多个进程之间共享同一块内存，需要同步机制保护
			4. 信号量：通过信号量控制进程对资源的访问权限，线程池使用的就是这种思想，主要是用于控制进程同步
				1. 如何实现：例如信号量为01，为0则允许访问，为1则不允许
				2. 如何实现多个线程同步：根据操作系统中的pv操作，设置信号量为大于1的值，每次申请资源则信号量-1，释放资源，则信号量+1,当信号量为0时，则说明现在没有可用资源
			5. 套接字：一般用于网络通信，实现：tcp、ssl
			6. 信号：一般用于关闭通知或者中断通知
4. 基础知识
5. hashMap底层
	1. 底层数据结构：数组+链表+红黑树。默认链表长度超过8时转化为红黑树。默认负载因子0.75。
		1. 数组通过哈希直接定位桶
		2. 链表解决哈希冲突
		3. 红黑树防止链表过长
	2. 扩容机制，初始容量16，扩容为翻倍。
		1. 容量为2的幂次方容量的原因是使用位运算更快
		2. 插入过程：根据存储数据的key计算哈希值，根据哈希值确认桶的位置，如果当前位置已经存在元素，存储值链表中，如果链表长度超过8，则转化为红黑树。如果元素数量超过阈值（负载因子*容量）进行扩容，
		3. 哈希冲突解决
			1. 哈希冲突解决
				1. 链表法：在相同位置时，使用链表存储元素，元素过长，则使用hash表存储元素
				2. 开放寻址法
					1. 再哈希：进行两次哈希取值
					2. 线性探测：在哈希去之上加上一个线性取数
					3. 平方探测：加上平方值
		4. 扩容的具体操作：
			1. 创建一个新数组
			2. 旧数据迁移至新数组（新位置=原位置或者原位置+旧容量），更新位置的计算方式：旧的索引值在二进制下高位如果为一，则索引值为旧索引值新增一个高位（原来容量为8-->421，现在16-->8421，低位不变，新增了一个高位）
6.  hashMap为线程不安全，ConcurrentHashMap为线程安全，如何实现：Java8通过cas以及synchronized实现
		1. 在对应桶位置为空时，通过cas原子操作，桶不为空时，通过synchronized锁定链表或者树的头节点，插入元素
		2. 为什么synchronized只锁定头节点：锁粒度最小化，这样可以保证不同桶节点的元素之间没有锁竞争
		3. java7的concurrentHashMap实现：通过对hashMap分段加锁实现，最多16个锁，缺陷在于一个段内可能会有多个桶存在
		4. 1. concurrentHashMap真的线程安全么，在什么情况下，线程不安全
			1. concurrentHashMap仅保证多线程间的原子操作读写安全（单节点单方法操作），也就是说多个线程在对当前容器的操作之间互不影响，但是如果是同时对多个节点同时操作就可能线程不安全
			2. 不安全的情况：一般来说是使用了map容器的当前状态进行判断，然后做处理
			3. 复合操作：在put时先判断当前key是否存在，由于多线程状态下map的数据可能处于一个中间态，可能会出现线程不安全
			4. 操作后更新：在put时先从map中获取当前数据，对数据进行操作后，再加入到map中
			5. 大小操作：通过对map中的元素个数进行判断然后操作，其他线程可能已经修改了当前map的元素
			6. 批量操作：多线程进行for循环遍历，map中元素可能已经出现了变化
7. 常用排序算法-思想
	1. 快排
		1. 算法思想：在所有元素中，选取一个基准值，将所有元素分为左右两个序列，递归左右序列，使得每个子序列中基准值左边的元素小于基准值，右边的元素大于基准值
		2. 关键要点：
			1. 三数中取基准值：随机选取，或者左中右选中位数
			2. 每一次的操作我们只需满足左边小于基准值，右边大于基准值，左右区间的顺序我们并不关心
	2. 归并排序
		1. 算法思想：将所有元素递归的分为两半，将两个子数组合并到一个数组中（新增一个临时数组存储数据，结束后拷贝排序后的数据到原数组中），当数组长度为1时，数据自有序
	3. 堆排序
		1. 算法思想：将元素构建成最大堆（父节点>=子节点），重复将最大元素与末尾元素交换，并且调整堆
		2. 关键要点：堆顶元素最大，递归处理堆堆顶之下的其他数据
8. mysql以及clickHouse的区别，实现原理，ck的数据库引擎
	1. 1. mysql是关系型数据库，在事务处理方面性能优异，ck是列示分析性数据库，在数据检索分析方面性能优异。mysql支持行级更新，ck主要以批量追加为主，更新能力有限。mysql支持完整的acid事务支持，ck不支持事务。
	2. mysql的存储引擎（innoDb），ck的存储引擎（mergeTree）
		1. innodb：数据行级存储，使用b+树作为索引
			1. 为什么使用b+树：主键索引和数据绑定，叶子结点直接存储行数据（聚集索引）
			2. 聚集索引和二级索引：聚集索引就是主键索引，主键为索引，叶子结点中存储了所有的行数据。二级索引就是我们平时的非主键索引，叶子结点存储了主键值，查询到主键值，回表查询主键数，从主键树的叶子结点拿到对应的列数据
				1. 聚集索引按照主键排序，这也是为什么建议使用自增id。二级索引按照索引列排序
				2. 索引优化场景：查询数据直接为索引，这样就无需回表查询
		2.  mergeTree：数据列式存储，使用稀疏索引、数据合并，批量处理数据等机制
			1. 为什么使用列式存储，列式存储是通过什么实现的：通过列式存储，可以提高查询性能，仅查询想要的列数据，且支持高效的聚合操作。ck通过对列数据在存储引擎中通过.bin文件存储，通过.mk2文件标记列数据在文件中的位置
	3. 执行流程差异
		1. 相同点：
			1. 执行流程都是：权限判断-sql解析分析-sql优化-sql执行，数据读取，返回数据
			2. 语句执行流程：FROM -> JOIN -> ON -> WHERE -> GROUP BY -> HAVING -> SELECT -> ORDER BY -> LIMIT
		2. 不同点：
			1. mysql的from加载所有的行，ck仅加载需要的列，mysql的where逐行过滤，ck批量过滤，
9. mysql的多个数据引擎，常见调优，常见索引，最左索引是什么
	1. 常见数据存储引擎：
		1. innodb：默认的搜索引擎，在各个方面的性能较为均衡
		2. myIsam：不支持事务，表级锁，适用于只读
		3. memory：数据存储到内存中
	2. 常见调优方式
		1. 使用最左前缀原则：最左前缀原则指的是在使用组合索引时，查询条件必须从索引的最左列开始，不能跳过中间的列
			1. 为什么：索引具有覆盖索引的优化，如果不遵从这个原则，那么将不会查询索引
		2. 使用有序主键：存储引擎中数据的物理存储顺序是根据主键来的，有序的话占用空间有序，占用较小，范围查询时顺序遍历更高效
	3. 覆盖索引：使用索引覆盖，可以减少回表查询，在索引中可以直接拿到数据，无需拿叶子结点的id去主键索引中回表
	4. 优先使用组合索引，组合索引有限覆盖高频列
10. gc原理-常见内存处理方式
	1. 什么是gc：垃圾回收，自动管理内存的机制，回收不再使用的对象
	2. gc基本原理
		1. 对象存活判定：
			1. 引用计数法：记录对象引用次数，引用次数为0时清除。实现简单，但是无法处理循环饮用
			2. 可达性分析：从根对象标记所有可用对象，未被标记则清除。
		2. 垃圾回收算法
			1. 标记清除算法：标记可达对象，清除未标记的对象。实现简单，但是会有内存碎片
			2. 标记整理算法：标记可达对象，整理内存，清除碎片。实现复杂，整理成本高
			3. 复制算法：将内存分为两块，存活对象复制到另一块内存，清空当前块。无内存碎片，但是内存利用率只有一半
			4. 分代收集：java使用的就是这个，不同代使用不同的回收算法。新生代（eden-from/to）使用复制算法，老年代使用标记清除或者标记整理算法
	3. 常见gc调优
		1. 调整新生代的分区比例，一般eden：survivor=8:1
		2. 设置新生代大小，设置初始化堆大小
		3. 设置gc算法：使用G1垃圾回收器
11. redis的集群处理，redis的分片，redis想要新增集群节点，会执行什么流程，redis的负载均衡如何实现，如何保证新的key-value进入新增的集群节点，redis的持久化分布，分布式调用redis如何保证两次请求不会重复
	1. redis的集群处理以及redis的分片
		1. 集群处理：redis官方提供了主从节点模式，可以直接使用，自动提供故障转移能力，可以理解为只有一个机器，从节点有着和主节点相同的数据，当主节点故障时，会自动将流量代理到从节点上
		2. 分片处理：客户端通过代理转发实现水平分区，可以理解为多个机器，通过代理的转发算法，代理到不同的机器上，如果一个机器发生故障，需要手动处理转发
			1. 代理分片：通过代理转发，将请求转发到不同的redis节点中
			2. 客户端分片：通过客户端计算redis的每一个key应该存储的分区，出现故障处理比较复杂
			3. 哈希槽分区：官方支持的分片利用redis的集群处理实现，故障自动转移
		3. 两者的区别：redis的集群处理和redis的分片处理，可以理解为一个东西，redis的哈希槽分片处理就是利用的redis的集群处理，这是官方提供的能力，redis的集群处理除了分片还实现了其他复杂的功能
	2. redis新增集群节点，执行的流程：
		1. 扩容
			1.  新节点加入集群 (`CLUSTER MEET`)
			2. 批量迁移键值对数据到新节点
			3. 更新集群配置
			4. 平衡节点负载
		2. 缩容
			1. 迁移待移除节点的键值对数据
			2. 通知集群忘记节点
			3. 关闭节点服务
			4. 平衡节点负载
	3. redis的负载均衡：哈希槽分区
		1. redis通过哈希槽分区来实现负载均衡，redis集群在创建的时候，会在每个节点中管理一部分的哈希槽（哈希槽中就是数据）
		2. redis通过哈希算法（redis访问或者存储一个key都会通过哈希算法计算位置）保证key均匀的分布在所有哈希槽中，也可以理解为均匀的分布在不同的redis节点中
		3. 扩容或者缩容时，每个节点管理的哈希槽会重新分配
		4. 优化点：可以进行读写分离，将读操作到从节点上进行（主节点和从节点数据是一样的）；或者手动划分哈希槽
	4. redis的持久化分布
		1. 数据快照（RDB）：通过创建数据集快照（也就是当前的redis中保存的数据集），优点是文件小，并且加载快，缺点是在快照后的数据无法保存
		2. 追加日志文件（AOF）：通过记录redis的每一次写操作，写入操作通过追加写入的方式，实现对redis数据的记录。优点是记录每一次的写入操作，缺点是恢复速度比较慢
		3. 优化方式：两者同时使用，定期备份数据快照，同时追加写入日志，在数据丢失时，通过RDB恢复一部分数据，然后通过重放aof恢复最后一次快照之后的数据（redis4.0版本已经支持）
	5. 分布式调用redis如何保证两次请求不重复
		1.  redis通过哈希槽分区机制来将每一个key映射到唯一的节点中
		2. redis支持事务机制，也有分布式锁，如果由于网络重试或者其他原因导致redis接受了两个相同的请求，redis自己并不会做处理，redis只保证命令顺序执行，不会检测重复请求，如果希望避免这种重复请求，需要客户端自行实现，比如为请求生成一个唯一id或者lua脚本实现等
12. ng的负载均衡，算法具体如何实现，如何保证这个请求到指定的服务中
	1. ng的负载均衡算法
		1. 轮询：计算每一个服务器的权重，选择最大的哪一个
			1. 默认轮询，按顺序分配
			2. 加权轮询：通过参数分配权重
		2. 最少链接：优先分配给当前连接数最少的服务器，ng为每一个服务器维护了一个连接计数器，在分配时根据这个计数器，将连接转发到连接数最少的那个服务器
	2. ng通过域名路由配置或者路径前缀配置，来将对应的请求转发到对应的后台服务中。如果是这个请求是如何从客户端到达后端服务，这就需要dns域名解析，ip路由寻址转发，再到ng的代理（http的流程）
13. mongdb的基本使用，实现原理
	1. mongodb是基于bjson格式存储的文档型数据库，支持嵌套结构，无需预定义表结构，字段可以动态删减，支持通过分片进行水平扩展
	2. 和关系型数据库的区别是：关系型的表在mongdb中是集合，行是文档，列是属性
	3. 默认存储引擎：wiredTiger
14. mq的使用，mq的消息堆积，mq的消息丢失
	1. 使用场景：
		1. 异步处理
		2. 系统解耦
		3. 流量削峰
		4. 分布式事务
	2. 常见问题
		1. 消息堆积
			1. 增加消费者实例
			2. 批量消费消息
			3. 将消息写入死信队列，人工处理
		2. 消息重复
			1. 为消息添加唯一id，处理前检查处理状态
			2. 业务逻辑去重（主键唯一或者业务处理）
		3. 消息丢失
			1. 生产者使用异步回调确认消息+消息重试
			2. 消费者处理完成后手动确认，使用数据库唯一主键以及事务控制
		4. 消息乱序
			1. 使用kafka，相同key的消息会被写入到东一个分区
15. dubbo和zk
	1. 简介
		1. dubbo：dubbo是一块高性能rbc框架，主要用于分布式服务治理，核心功能有服务自动注册、负载均衡、服务容错、服务治理等
		2. zk：分布式协调服务，一般用作注册中心（nacos也可以用作注册中心）
	2. dubbo与zk的协作：
		1. 服务注册：项目启动时，dubbo的provider想zk注册服务地址
		2. 服务发现：consumer从zk订阅服务地址列表，并缓存服务本地
		3. 健康检测：provider和zk保持心跳健康检测，当provider移除了节点或者断连时，zk自动移除节点（zk宕机时，可以使用dubbo本地缓存的服务列表）
	3. dubbo的服务治理以及服务容错是怎么实现的
		1. 服务治理
			1. 服务注册：通过与zk/nacos等注册中心维护
				1. 生产者向zk注册服务地址，消费者向zk获取服务地址，服务中动态生成对应类，进行调用
			2. 负载均衡
				1. 随机
				2. 加权轮询（算法与ng一致）
				3. 最少活跃调用
			3. 限流：dubbo的生产者可以实现限流处理
		2. 服务容错
			1. 熔断降级：dubbo有提供配置，可以设置降级调用的服务接口
			2. 失败重试配置
	4. 除了dubbo和zk，还用过其他相关的类似服务么
		1. 客户端
		2. 网关：shenyu、springcloudGateway
		3. 用户服务集群：dubbo、grpc、springcloud
		4. 注册中心：zookeeper、nacos
		5. 配置中心：apollo、springcloudconfig
		6. 消息队列
		7. 监控体系：skywalking
	5. dubbo的注册机制以及zk的注册机制
		1. dubbo注册：
			1. 生产者通过配置或者注解启用注册，服务启用nety服务监听端口，想注册中心写入服务元数据
			2. 消费者通过配置或注解自动订阅，从注册中心拉去服务列表，根据列表中的服务元数据，生成代理对象，执行方法
	6. 如果一个分布式服务突然关闭，在zk注册中心中对应的数据会删除么，如果会删除，通过什么方式，如果不会，为什么
		1. 正常会话关闭，zk会自动删除对应的注册信息
		2. 服务突然关闭，比如程序崩溃，由于心跳健康检查的存在，并不会及时删除，会等到绘画超时后，才会删除
	7. zk在服务中启用流程是什么样的：直接在应用启用时，配置dubbo的注册中心配置为dubbo的地址即可
	8. zk除了用作服务注册还可以用做什么
		1. 可以用作分布式配置管理（同apollo）
		2. 命名服务：可以用于全局唯一id生成，id严格单调递增，且包含日期信息
			1. 顺序节点：zk在创建节点时添加顺序标识，会自动追加递增序列号（10位十进制数）
			2. 通过原子广播协议保证所有节点的顺序不冲突

16. nacos一般用作什么，apollo呢，两者的实现原理是什么
17. linux下的排查问题过程，cpu占用过高、内存溢出等
	1. cpu占用过高（如何确定是哪一个类导致的cpu占用过高）
		1. top命令查看当前服务cpu占用，按p排序
		2. ps pid命令查看占用最高的服务
		3. 查看当前占用线程最高的线程pid
		4. 将线程pid转化为16进制
		5. 在线程快照中根据16进制的id查看对应调用栈
			1. 线程快照信息包括：16进制id+当前代码栈+运行状态
		6. 追溯代码问题(可以根据eclips提供的mat工具，来进行可视化分析)
	2. 内存溢出
		1. free -m 查看内存使用情况
		2. 通过ps pid命令查看内存占用最高的服务
		3. 生成堆栈快照，分析
	3. 通过jvm参数监控服务占用
		1. 内存溢出：
			1. 在 OOM 时自动生成堆转储-XX:+HeapDumpOnOutOfMemoryError
			2. 指定堆转储文件路径-XX:HeapDumpPath=/path/to/dump
		2. [ ] cpu占用：无合适方法，实时打印线程浪太大
		3. 可以通过prometheus来实现对java服务的内存监控
18. top命令中的cpu占用linux系统是如何计算的
	1. 计算方式：当前服务使用cpu的时间除以总时间
		1. 使用时间=cpu总时间-空闲时间-io等待时间
19. 有哪些具体的生产调优过程，最后发现问题是什么，如何解决
	1.  cpu占用过高：top命令+线程快照+代码溯源
	2. 内存溢出：free+堆转储文件+代码溯源
	3. 慢查询故障：通过慢查询日志分析，定位到对应的sql，对sql进行分析，通过添加索引或者查询条件优化（例如：时间可以通过携带日期的主键id范围查询），添加缓存
20. rbac是什么，除了rbac，还了解别的权限管理么，这几种权限管理模型各有什么优缺点，适用场景是什么
	1. rbac：基于角色作为权限控制的载体，用户分配角色实现权限控制
		1. 优点：修改角色可以批量更新用户权限，无需为每个用户设置权限
		2. 缺点：复杂系统，角色数量可能极多，无法根据属性资源动态控制
		3. 适用于公司内部管理系统，权限要求不高
	2. acl：直接在资源层面上控制权限
		1. 优点：权限控制粒度细，精确到具体资源
		2. 缺点：无法批量管理用户权限，资源量大会导致维护困难
	3. abac：基于属性的访问控制，通过属性动态控制权限
		1. 优点：支持复杂的权限控制逻辑，权限控制粒度精确到字段
		2. 缺点：实现复杂，多属性组合逻辑控制复杂
	4. pbac：基于策略的访问控制，结合了rbac+abac的管理
		1. 优点：支持灵活拓展，结合了abac以及rbac的动态权限控制能力
		2. 缺点：设计复杂，配置复杂
21. 登陆注册日志落库流程是什么样的，日志数据为什么是这么生成的，为什么这么做，通过什么避免消息重复以及id重复
	1. 落库逻辑
		1. 客户端点击登录，前端填充参数发起请求到后端
		2. 网关对请求进行校验，验证通过则放行至后端认证服务
		3. 后端认证服务根据传入的登录参数，进行不同的登录校验
		4. 登录校验通过，填充登录日志，通过zk生成分布式唯一id，发送到消息队列
		5. 消息队列消费消息，将登录日志入库
		6. 有提供消息队列监控，当发生消息堆积，动态增加消费者
	2. 避免消息重复
		1. 前端进行防抖处理
		2. 生成分布式唯一id
		3. 数据库唯一约束
		4. 消息队列消费时根据分布式唯一id做处理（通过缓存或者一分钟的内存处理）
22. 对大数据量的数据，进行操作，有什么需要注意的地方，如果需要对这个表操作进行调优，应该怎么做，有哪些常用的sql调优方式，如何进行读写分离
	1. 操作注意事项
		1. 写入
			1. 更新时避免进行全表更新，在更新时增加条件，最好能够使得条件为id
			2. 插入时，尽量使用批量插入，而不是批量多次插入
		2. 读取
			1. 避免全表进行扫描，能使用索引，就使用索引（索引覆盖/最左前缀）
			2. 分页时，尽量使用limit X,而不是limit x,y（因为limit会先执行到x条数，在基于这个位置去进行分页）
		3. 数据结构变更
			1. 数据结构变更时，通过pt工具实现，这种方式不会锁表，可以降低对业务的影响
	2. sql调优
		1. 索引优化：索引覆盖，使用最左前缀原则，避免使用会导致全表扫描或者不走索引的sql
		2. 查询重写：
	3. 读写分离
		1. springboot可以通过配置直接实现
	4. 分库分表策略（建议直接使用ck）
		1. 垂直分表：将一个表分为多个单独的小表
		2. 水平分片：
23. 三方平台的标准化插件的开发流程是什么样的，开发完成后执行流程是什么样的，为什么要基于groovy脚本开发插件，如何避免groovy脚本执行非法操作
24. 如何实现三方平台的高并发处理
	1. http链接池+多线程：通过构建http连接池，通过多线程访问链接吃，进行http接口调用。连接复用，异步执行提升吞吐量
	2. 配置缓存：请求插件配置通过本地缓存定时更新实现，提升配置读取效率
	3. 通过动态限流算法控制流量：通过滑动窗口限制请求并发量，请求超出，将其加入阻塞队列等待后续调用
	4. 调用记录通过mq异步存储：请求调用日志通过mq异步存储优化
	5. 加机器：kubernetes自动扩容
25. 数据采集平台的作用，为什么要开发这么一个系统，系统的实现原理是什么
	1. 主要是为了方便业务部门取数，同时接入oa实现流程规范，通过系统实现取数相对人工取数更为安全
26. bi报表为什么要划分pc端以及移动端，如何实现数据权限控制，在bi报表中，缓存优化体现在哪些方面
	1. 由于相关报表设计敏感数据，pc端仅支持内网访问，不支持外网访问，提供移动端支持外网访问
	2. 数据权限控制：基于rbac，配置用户角色，设置用户可见报表菜单，设置访问行为监控
	3. bi报表中缓存优化：移动端均展示图片，通过缓存图片url，实现移动端报表毫米级响应
27. springcloud中的注册中心是哪一个
28. java中的服务治理通过什么
29. 通过hashmap设计一个缓存，内存有限，但是可能需要存储的数据无限
	1. 思路：concurrentHashMap作为缓存存储结构，存储key-value，加入缓存时value进行对应的数据压缩，当内存已满时，使用对应的内存淘汰机制，删除当前已有的内存，设置过期处理，清除过期缓存
	2.  过期处理详情
		1. 定期刷数据
	3. 内存淘汰机制详情(java的LinkedHashMap可以直接实现，这个属性里面有一个)
		1. 先入先出：维护一个列表，存储缓存的key即可，需要淘汰，则从尾部获取key，从map中移除
		2. 最近最少使用：
	4. 数据压缩:java中提供了GZIPOutputStream类，来实现数据的压缩和解压缩
30. 有没有在高并发场景下遇到变量不一致的问题，如何解决的，或者说如何解决高并发状态下不同线程变量不一致的问题
	1.   使用hashmap没有遇到过线程不安全，因为一般在多线程操作下面，都是使用ConcurrentHashMap进行操作，不过在使用ConcurrentHashMap的时候遇到过执行结果和预期不一致的问题
		1. 问题详情：在三方平台中，有一个操作逻辑是在put时，根据原有数据进行操作，然后更新map中数据（当前数据产品的调用量埋点，调用量+1），由于埋点是实时的，所以直接在内存中维护了这个map进行埋点，原有逻辑是先获取当前调用量进行+1之后在put入map中，后面发现埋点数据量和日志统计调用量不一致，三方平台中埋点记录量较低
		2. 为什么要进行这个操作：qps高于100/s，有时需要记录实时调用量，调用日志落库通过消息队列异步存储有统计延时
		3. 排查流程：首先是对这一块代码进行了代码review，发现使用的是concurrentHashMap，认为没有线程问题（实际是有），然后在该位置添加了部分日志，在本地通过压力测试进行多线程操作模拟，观察执行结果
		4. 问题详情：通过模拟测试，发现问题在于concurrentHashMap在进行数值操作时，多个线程在获取调用量时可能会出现获取到相同数量的value，导致本应+2的操作变成了+1。问题本质在于，concurrentHashMap只支持单个操作的原子性，多个原子操作组合之间可能被其他线程修改数据，导致线程不安全
		5. 解决办法：基于当前场景，只需避免进行原子操作组合即可，concurrentHashMap提供了compute原子方法来对k、v进行自定义操作保证线程安全。针对其他不安全场景， 可以通过对执行流程加锁实现
31. 使用hashmap的过程中有没有遇到过线程不安全的情况，如何解决的
32. 慢查询的优化
33. 压力测试工具的使用