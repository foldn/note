1. 计算机网络

1. http1.0和http2.0的区别，优化点
	1. http网络连接，如何实现通信，如何保证通信顺序
	2. 为什么使用长连接，使用长连接的优点是什么，一次连接只能进行一个请求么，如果可以多个，通过什么实现，如何保证多个请求的返回体能够返回给对应的请求服务器
2. 操作系统还记得什么知识
3. 操作系统如何保证线程安全（同步机制）
	1. 高并发情况下通过cas或者读写锁更优
		1. cas原子操作：通过硬件原子操作实现
			1. cas原子操作的ABA问题：我们修改的前提是V和E相等，有可能我们进行修改的过程中，V的值已经发生过变化，然后又变化回来了（A-B-A）
			2. ABA问题的解决：通过对V新增一个版本号，根据版本号确定是否一致
		2. 互斥机制：通过互斥锁、自旋锁（临界区是同一个时间只允许一个线程访问的系统资源，必须使用同步机制保护，例如文件系统）
			1. 互斥锁（适用于临界区操作时间长）：同一时间只允许一个线程访问，其他线程访问，将其加到阻塞队列中，待当前线程执行完，开始执行阻塞队列头部线程
			2. 自旋锁（适用于临界区操作时间短，多cpu环境）：当前资源被一个线程访问时，其他线程请求访问，不会被阻塞，而是通过循环访问当前资源，查看是否已被上一个线程释放
		3. 内存屏障：通过内存屏障强制指定指令的执行顺序，由于多线程的环境，编译器可能会对指令进行重排序，因此通过内存屏障可以防止执行乱序执行
		4. 优先继承协议：高优先级进程被低优先级进程阻塞，暂时提升低优先级进程的优先级，使其快速执行完成释放资源，然后恢复锁
		5. 进程间通信：管道、消息队列、共享内存、信号量、套接字、信号等
			1. 管道：数据单向流动，从父节点流动到子节点或者子节点到父节点，两者间有一个通信通道
			2. 消息队列：消息队列间通过消息体内设置的标识符来进行通信
			3. 共享内存：多个进程之间共享同一块内存，需要同步机制保护
			4. 信号量：通过信号量控制进程对资源的访问权限，线程池使用的就是这种思想，主要是用于控制进程同步
				1. 如何实现：例如信号量为01，为0则允许访问，为1则不允许
				2. 如何实现多个线程同步：根据操作系统中的pv操作，设置信号量为大于1的值，每次申请资源则信号量-1，释放资源，则信号量+1,当信号量为0时，则说明现在没有可用资源
			5. 套接字：一般用于网络通信，实现：tcp、ssl
			6. 信号：一般用于关闭通知或者中断通知
4. 基础知识
5. hashMap底层
	1. 底层数据结构：数组+链表+红黑树。默认链表长度超过8时转化为红黑树。默认负载因子0.75。
		1. 数组通过哈希直接定位桶
		2. 链表解决哈希冲突
		3. 红黑树防止链表过长
	2. 扩容机制，初始容量16，扩容为翻倍。
		1. 容量为2的幂次方容量的原因是使用位运算更快
		2. 插入过程：根据存储数据的key计算哈希值，根据哈希值确认桶的位置，如果当前位置已经存在元素，存储值链表中，如果链表长度超过8，则转化为红黑树。如果元素数量超过阈值（负载因子*容量）进行扩容，
		3. 哈希冲突解决
			1. 哈希冲突解决
				1. 链表法：在相同位置时，使用链表存储元素，元素过长，则使用hash表存储元素
				2. 开放寻址法
					1. 再哈希：进行两次哈希取值
					2. 线性探测：在哈希去之上加上一个线性取数
					3. 平方探测：加上平方值
		4. 扩容的具体操作：
			1. 创建一个新数组
			2. 旧数据迁移至新数组（新位置=原位置或者原位置+旧容量），更新位置的计算方式：旧的索引值在二进制下高位如果为一，则索引值为旧索引值新增一个高位（原来容量为8-->421，现在16-->8421，低位不变，新增了一个高位）
6.  hashMap为线程不安全，ConcurrentHashMap为线程安全，如何实现：Java8通过cas以及synchronized实现
		1. 在对应桶位置为空时，通过cas原子操作，桶不为空时，通过synchronized锁定链表或者树的头节点，插入元素
		2. 为什么synchronized只锁定头节点：锁粒度最小化，这样可以保证不同桶节点的元素之间没有锁竞争
		3. java7的concurrentHashMap实现：通过对hashMap分段加锁实现，最多16个锁，缺陷在于一个段内可能会有多个桶存在
7. 常用排序算法-思想
	1. 快排
		1. 算法思想：在所有元素中，选取一个基准值，将所有元素分为左右两个序列，递归左右序列，使得每个子序列中基准值左边的元素小于基准值，右边的元素大于基准值
		2. 关键要点：
			1. 三数中取基准值：随机选取，或者左中右选中位数
			2. 每一次的操作我们只需满足左边小于基准值，右边大于基准值，左右区间的顺序我们并不关心
	2. 归并排序
		1. 算法思想：将所有元素递归的分为两半，将两个子数组合并到一个数组中（新增一个临时数组存储数据，结束后拷贝排序后的数据到原数组中），当数组长度为1时，数据自有序
	3. 堆排序
		1. 算法思想：将元素构建成最大堆（父节点>=子节点），重复将最大元素与末尾元素交换，并且调整堆
		2. 关键要点：堆顶元素最大，递归处理堆堆顶之下的其他数据
8. mysql以及clickHouse的区别，实现原理，ck的数据库引擎
	1. 1. mysql是关系型数据库，在事务处理方面性能优异，ck是列示分析性数据库，在数据检索分析方面性能优异。mysql支持行级更新，ck主要以批量追加为主，更新能力有限。mysql支持完整的acid事务支持，ck不支持事务。
	2. mysql的存储引擎（innoDb），ck的存储引擎（mergeTree）
		1. innodb：数据行级存储，使用b+树作为索引
			1. 为什么使用b+树：主键索引和数据绑定，叶子结点直接存储行数据（聚集索引）
			2. 聚集索引和二级索引：聚集索引就是主键索引，主键为索引，叶子结点中存储了所有的行数据。二级索引就是我们平时的非主键索引，叶子结点存储了主键值，查询到主键值，回表查询主键数，从主键树的叶子结点拿到对应的列数据
				1. 聚集索引按照主键排序，这也是为什么建议使用自增id。二级索引按照索引列排序
				2. 索引优化场景：查询数据直接为索引，这样就无需回表查询
		2.  mergeTree：数据列式存储，使用稀疏索引、数据合并，批量处理数据等机制
			1. 为什么使用列式存储，列式存储是通过什么实现的：通过列式存储，可以提高查询性能，仅查询想要的列数据，且支持高效的聚合操作。ck通过对列数据在存储引擎中通过.bin文件存储，通过.mk2文件标记列数据在文件中的位置
	3. 执行流程差异
		1. 相同点：
			1. 执行流程都是：权限判断-sql解析分析-sql优化-sql执行，数据读取，返回数据
			2. 语句执行流程：FROM -> JOIN -> ON -> WHERE -> GROUP BY -> HAVING -> SELECT -> ORDER BY -> LIMIT
		2. 不同点：
			1. mysql的from加载所有的行，ck仅加载需要的列，mysql的where逐行过滤，ck批量过滤，
9. mysql的多个数据引擎，常见调优，常见索引，最左索引是什么
	1. 常见数据存储引擎：
		1. innodb：默认的搜索引擎，在各个方面的性能较为均衡
		2. myIsam：不支持事务，表级锁，适用于只读
		3. memory：数据存储到内存中
	2. 常见调优方式
		1. 使用最左前缀原则：最左前缀原则指的是在使用组合索引时，查询条件必须从索引的最左列开始，不能跳过中间的列
			1. 为什么：索引具有覆盖索引的优化，如果不遵从这个原则，那么将不会查询索引
		2. 使用有序主键：存储引擎中数据的物理存储顺序是根据主键来的，有序的话占用空间有序，占用较小，范围查询时顺序遍历更高效
	3. 覆盖索引：使用索引覆盖，可以减少回表查询，在索引中可以直接拿到数据，无需拿叶子结点的id去主键索引中回表
	4. 优先使用组合索引，组合索引有限覆盖高频列
10. gc原理-常见内存处理方式
	1. 什么是gc：垃圾回收，自动管理内存的机制，回收不再使用的对象
	2. gc基本原理
		1. 对象存活判定：
			1. 引用计数法：记录对象引用次数，引用次数为0时清除。实现简单，但是无法处理循环饮用
			2. 可达性分析：从根对象标记所有可用对象，未被标记则清除。
		2. 垃圾回收算法
			1. 标记清除算法：标记可达对象，清除未标记的对象。实现简单，但是会有内存碎片
			2. 标记整理算法：标记可达对象，整理内存，清除碎片。实现复杂，整理成本高
			3. 复制算法：将内存分为两块，存活对象复制到另一块内存，清空当前块。无内存碎片，但是内存利用率只有一半
			4. 分代收集：java使用的就是这个，不同代使用不同的回收算法。新生代（eden-from/to）使用复制算法，老年代使用标记清除或者标记整理算法
	3. 常见gc调优
		1. 调整新生代的分区比例，一般eden：survivor=8:1
		2. 设置新生代大小，设置初始化堆大小
		3. 设置gc算法：使用G1垃圾回收器
11. redis的集群处理，redis的分片，redis想要新增集群节点，会执行什么流程，redis的负载均衡如何实现，如何保证新的key-value进入新增的集群节点，redis的持久化分布，分布式调用redis如何保证两次请求不会重复
	1. redis的集群处理以及redis的分片
		1. 集群处理：redis官方提供了主从节点模式，可以直接使用，自动提供故障转移能力，可以理解为只有一个机器，从节点有着和主节点相同的数据，当主节点故障时，会自动将流量代理到从节点上
		2. 分片处理：客户端通过代理转发实现水平分区，可以理解为多个机器，通过代理的转发算法，代理到不同的机器上，如果一个机器发生故障，需要手动处理转发
			1. 代理分片：通过代理转发，将请求转发到不同的redis节点中
			2. 客户端分片：通过客户端计算redis的每一个key应该存储的分区，出现故障处理比较复杂
			3. 哈希槽分区：官方支持的分片利用redis的集群处理实现，故障自动转移
		3. 两者的区别：redis的集群处理和redis的分片处理，可以理解为一个东西，redis的哈希槽分片处理就是利用的redis的集群处理，这是官方提供的能力，redis的集群处理除了分片还实现了其他复杂的功能
	2. redis新增集群节点，执行的流程：
		1. 扩容
			1.  新节点加入集群 (`CLUSTER MEET`)
			2. 批量迁移键值对数据到新节点
			3. 更新集群配置
			4. 平衡节点负载
		2. 缩容
			1. 迁移待移除节点的键值对数据
			2. 通知集群忘记节点
			3. 关闭节点服务
			4. 平衡节点负载
	3. redis的负载均衡：哈希槽分区
		1. redis通过哈希槽分区来实现负载均衡，redis集群在创建的时候，会在每个节点中管理一部分的哈希槽（哈希槽中就是数据）
		2. redis通过哈希算法（redis访问或者存储一个key都会通过哈希算法计算位置）保证key均匀的分布在所有哈希槽中，也可以理解为均匀的分布在不同的redis节点中
		3. 扩容或者缩容时，每个节点管理的哈希槽会重新分配
		4. 优化点：可以进行读写分离，将读操作到从节点上进行（主节点和从节点数据是一样的）；或者手动划分哈希槽
	4. redis的持久化分布
		1. 数据快照（RDB）：通过创建数据集快照（也就是当前的redis中保存的数据集），优点是文件小，并且加载快，缺点是在快照后的数据无法保存
		2. 追加日志文件（AOF）：通过记录redis的每一次写操作，写入操作通过追加写入的方式，实现对redis数据的记录。优点是记录每一次的写入操作，缺点是恢复速度比较慢
		3. 优化方式：两者同时使用，定期备份数据快照，同时追加写入日志，在数据丢失时，通过RDB恢复一部分数据，然后通过重放aof恢复最后一次快照之后的数据（redis4.0版本已经支持）
	5. 分布式调用redis如何保证两次请求不重复
		1.  redis通过哈希槽分区机制来将每一个key映射到唯一的节点中
		2. redis支持事务机制，也有分布式锁，如果由于网络重试或者其他原因导致redis接受了两个相同的请求，redis自己并不会做处理，redis只保证命令顺序执行，不会检测重复请求，如果希望避免这种重复请求，需要客户端自行实现，比如为请求生成一个唯一id或者lua脚本实现等
12. ng的负载均衡，算法具体如何实现，如何保证这个请求到指定的服务中
	1. ng的负载均衡算法
		1. 轮询
			1. 默认轮询，按顺序分配
			2. 加权轮询：通过参数分配权重
		2. 最少链接：优先分配给当前连接数最少的服务器
13. 哈希冲突的解决，除了散列表和在哈希，还有什么方式
14. mongdb的基本使用，实现原理
15. mq的使用，mq的消息堆积，mq的消息丢失
16. 除了dubbo和zk，还用过其他相关的类似服务么
17. dubbo的注册机制以及zk的注册机制
18. dubbo和zk一般用来做什么
19. 如果一个分布式服务突然关闭，在zk注册中心中对应的数据会删除么，如果会删除，通过什么方式，如果不会，为什么
20. zk在服务中启用流程是什么样的
21. zk除了用作服务注册还可以用做什么

22. nacos一般用作什么，apollo呢，两者的实现原理是什么
23. linux下的排查问题过程，cpu占用过高、内存溢出等

24. top命令中的cpu占用linux系统是如何计算的
25. 有哪些具体的生产调优过程，最后发现问题是什么，如何解决

26. rbac是什么，除了rbac，还了解别的权限管理么，这几种权限管理模型各有什么优缺点，适用场景是什么
27. 登陆注册日志落库流程是什么样的，日志数据为什么是这么生成的，为什么这么做，通过什么避免消息重复以及id重复
28. 对大数据量的数据，进行操作，有什么需要注意的地方，如果需要对这个表操作进行调优，应该怎么做，有哪些常用的sql调优方式，如何进行读写分离
29. 三方平台的标准化插件的开发流程是什么样的，开发完成后执行流程是什么样的，为什么要基于groovy脚本开发插件，如何避免groovy脚本执行非法操作
30. 如何实现三方平台的高并发处理
31. 数据采集平台的作用，为什么要开发这么一个系统，系统的实现原理是什么
32. bi报表为什么要划分pc端以及移动端，如何实现数据权限控制，在bi报表中，缓存优化体现在哪些方面
33. springcloud中的注册中心是哪一个
34. java中的服务治理通过什么