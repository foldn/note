1. 计算机网络

1. http1.0和http2.0的区别，优化点
	1. http网络连接，如何实现通信，如何保证通信顺序
	2. 为什么使用长连接，使用长连接的优点是什么，一次连接只能进行一个请求么，如果可以多个，通过什么实现，如何保证多个请求的返回体能够返回给对应的请求服务器
2. 操作系统还记得什么知识
3. 操作系统如何保证线程安全（同步机制）
	1. 高并发情况下通过cas或者读写锁更优
		1. cas原子操作：通过硬件原子操作实现
			1. cas原子操作的ABA问题：我们修改的前提是V和E相等，有可能我们进行修改的过程中，V的值已经发生过变化，然后又变化回来了（A-B-A）
			2. ABA问题的解决：通过对V新增一个版本号，根据版本号确定是否一致
		2. 互斥机制：通过互斥锁、自旋锁（临界区是同一个时间只允许一个线程访问的系统资源，必须使用同步机制保护，例如文件系统）
			1. 互斥锁（适用于临界区操作时间长）：同一时间只允许一个线程访问，其他线程访问，将其加到阻塞队列中，待当前线程执行完，开始执行阻塞队列头部线程
			2. 自旋锁（适用于临界区操作时间短，多cpu环境）：当前资源被一个线程访问时，其他线程请求访问，不会被阻塞，而是通过循环访问当前资源，查看是否已被上一个线程释放
		3. 内存屏障：通过内存屏障强制指定指令的执行顺序，由于多线程的环境，编译器可能会对指令进行重排序，因此通过内存屏障可以防止执行乱序执行
		4. 优先继承协议：高优先级进程被低优先级进程阻塞，暂时提升低优先级进程的优先级，使其快速执行完成释放资源，然后恢复锁
		5. 进程间通信：管道、消息队列、共享内存、信号量、套接字、信号等
			1. 管道：数据单向流动，从父节点流动到子节点或者子节点到父节点，两者间有一个通信通道
			2. 消息队列：消息队列间通过消息体内设置的标识符来进行通信
			3. 共享内存：多个进程之间共享同一块内存，需要同步机制保护
			4. 信号量：通过信号量控制进程对资源的访问权限，线程池使用的就是这种思想，主要是用于控制进程同步
				1. 如何实现：例如信号量为01，为0则允许访问，为1则不允许
				2. 如何实现多个线程同步：根据操作系统中的pv操作，设置信号量为大于1的值，每次申请资源则信号量-1，释放资源，则信号量+1,当信号量为0时，则说明现在没有可用资源
			5. 套接字：一般用于网络通信，实现：tcp、ssl
			6. 信号：一般用于关闭通知或者中断通知
4. 基础知识
5. hashMap底层
	1. 底层数据结构：数组+链表+红黑树。默认链表长度超过8时转化为红黑树。默认负载因子0.75。
		1. 数组通过哈希直接定位桶
		2. 链表解决哈希冲突
		3. 红黑树防止链表过长
	2. 扩容机制，初始容量16，扩容为翻倍。
		1. 容量为2的幂次方容量的原因是使用位运算更快
		2. 插入过程：根据存储数据的key计算哈希值，根据哈希值确认桶的位置，如果当前位置已经存在元素，存储值链表中，如果链表长度超过8，则转化为红黑树。如果元素数量超过阈值（负载因子*容量）进行扩容，
		3. 哈希冲突解决
			1. 哈希冲突解决
				1. 链表法：在相同位置时，使用链表存储元素，元素过长，则使用hash表存储元素
				2. 开放寻址法
					1. 再哈希：进行两次哈希取值
					2. 线性探测：在哈希去之上加上一个线性取数
					3. 平方探测：加上平方值
		4. 扩容的具体操作：
			1. 创建一个新数组
			2. 旧数据迁移至新数组（新位置=原位置或者原位置+旧容量），更新位置的计算方式：旧的索引值在二进制下高位如果为一，则索引值为旧索引值新增一个高位（原来容量为8-->421，现在16-->8421，低位不变，新增了一个高位）
6.  hashMap为线程不安全，ConcurrentHashMap为线程安全，如何实现：Java8通过cas以及synchronized实现
		1. 在对应桶位置为空时，通过cas原子操作，桶不为空时，通过synchronized锁定链表或者树的头节点，插入元素
		2. 为什么synchronized只锁定头节点：锁粒度最小化，这样可以保证不同桶节点的元素之间没有锁竞争
		3. java7的concurrentHashMap实现：通过对hashMap分段加锁实现，最多16个锁，缺陷在于一个段内可能会有多个桶存在
7. 常用排序算法-思想
	1. 快排
		1. 算法思想：在所有元素中，选取一个基准值，将所有元素分为左右两个序列，递归左右序列，使得每个子序列中基准值左边的元素小于基准值，右边的元素大于基准值
		2. 关键要点：
			1. 三数中取基准值：随机选取，或者左中右选中位数
			2. 每一次的操作我们只需满足左边小于基准值，右边大于基准值，左右区间的顺序我们并不关心
	2. 归并排序
		1. 算法思想：将所有元素递归的分为两半，将两个子数组合并到一个数组中（新增一个临时数组存储数据，结束后拷贝排序后的数据到原数组中），当数组长度为1时，数据自有序
	3. 堆排序
		1. 算法思想：将元素构建成最大堆（父节点>=子节点），重复将最大元素与末尾元素交换，并且调整堆
		2. 关键要点：堆顶元素最大，递归处理堆堆顶之下的其他数据
8. mysql以及clickHouse的区别，实现原理，ck的数据库引擎
	1. 1. mysql是关系型数据库，在事务处理方面性能优异，ck是列示分析性数据库，在数据检索分析方面性能优异。mysql支持行级更新，ck主要以批量追加为主，更新能力有限。mysql支持完整的acid事务支持，ck不支持事务。
	2. mysql的存储引擎（innoDb），ck的存储引擎（mergeTree）
		1. innodb：数据行级存储，使用b+树作为索引
			1. 为什么使用b+树：主键索引和数据绑定，叶子结点直接存储行数据（聚集索引）
			2. 聚集索引和二级索引：聚集索引就是主键索引，主键为索引，叶子结点中存储了所有的行数据。二级索引就是我们平时的非主键索引，叶子结点存储了主键值，查询到主键值，回表查询主键数，从主键树的叶子结点拿到对应的列数据
				1. 聚集索引按照主键排序，这也是为什么建议使用自增id。二级索引按照索引列排序
				2. 索引优化场景：查询数据直接为索引，这样就无需回表查询
		2.  mergeTree：数据列式存储，使用稀疏索引、数据合并，批量处理数据等机制
			1. 为什么使用列式存储，列式存储是通过什么实现的：通过列式存储，可以提高查询性能，仅查询想要的列数据，且支持高效的聚合操作。ck通过对列数据在存储引擎中通过.bin文件存储，通过.mk2文件标记列数据在文件中的位置
	3. 执行流程差异
		1. 相同点：
			1. 执行流程都是：权限判断-sql解析分析-sql优化-sql执行，数据读取，返回数据
			2. 语句执行流程：FROM -> JOIN -> ON -> WHERE -> GROUP BY -> HAVING -> SELECT -> ORDER BY -> LIMIT
		2. 不同点：
			1. mysql的from加载所有的行，ck仅加载需要的列，mysql的where逐行过滤，ck批量过滤，
9. mysql的多个数据引擎，常见调优，常见索引，最左索引是什么
	1. 常见数据存储引擎：
		1. innodb：默认的搜索引擎，在各个方面的性能较为均衡
		2. myIsam：不支持事务，表级锁，适用于只读
		3. memory：数据存储到内存中
	2. 常见调优方式
		1. 使用最左前缀原则：最左前缀原则指的是在使用组合索引时，查询条件必须从索引的最左列开始，不能跳过中间的列
			1. 为什么：索引具有覆盖索引的优化，如果不遵从这个原则，那么将不会查询索引
		2. 使用有序主键：存储引擎中数据的物理存储顺序是根据主键来的，有序的话占用空间有序，占用较小，范围查询时顺序遍历更高效
	3. 覆盖索引：使用索引覆盖，可以减少回表查询，在索引中可以直接拿到数据，无需拿叶子结点的id去主键索引中回表
	4. 优先使用组合索引，组合索引有限覆盖高频列
10. gc原理-常见内存处理方式
	1. 什么是gc：垃圾回收，自动管理内存的机制，回收不再使用的对象
	2. gc基本原理
		1. 对象存活判定：
			1. 引用计数法：记录对象引用次数，引用次数为0时清除。实现简单，但是无法处理循环饮用
			2. 可达性分析：从根对象标记所有可用对象，未被标记则清除。
		2. 垃圾回收算法
			1. 标记清除算法：标记可达对象，清除未标记的对象。实现简单，但是会有内存碎片
			2. 标记整理算法：标记可达对象，整理内存，清除碎片。实现复杂，整理成本高
			3. 复制算法：将内存分为两块，存活对象复制到另一块内存，清空当前块。无内存碎片，但是内存利用率只有一半
			4. 分代收集：java使用的就是这个，不同代使用不同的回收算法。新生代（eden-from/to）使用复制算法，老年代使用标记清除或者标记整理算法
	3. 常见gc调优
		1. 调整新生代的分区比例，一般eden：survivor=8:1
		2. 设置新生代大小，设置初始化堆大小
		3. 设置gc算法：使用G1垃圾回收器
11. redis的集群处理，redis的分片，redis想要新增集群节点，会执行什么流程，redis的负载均衡如何实现，如何保证新的key-value进入新增的集群节点，redis的持久化分布，分布式调用redis如何保证两次请求不会重复
	1. redis的集群处理以及redis的分片
		1. 集群处理：redis官方提供了主从节点模式，可以直接使用，自动提供故障转移能力，可以理解为只有一个机器，从节点有着和主节点相同的数据，当主节点故障时，会自动将流量代理到从节点上
		2. 分片处理：客户端通过代理转发实现水平分区，可以理解为多个机器，通过代理的转发算法，代理到不同的机器上，如果一个机器发生故障，需要手动处理转发
			1. 代理分片：通过代理转发，将请求转发到不同的redis节点中
			2. 客户端分片：通过客户端计算redis的每一个key应该存储的分区，出现故障处理比较复杂
			3. 哈希槽分区：官方支持的分片利用redis的集群处理实现，故障自动转移
		3. 两者的区别：redis的集群处理和redis的分片处理，可以理解为一个东西，redis的哈希槽分片处理就是利用的redis的集群处理，这是官方提供的能力，redis的集群处理除了分片还实现了其他复杂的功能
	2. redis新增集群节点，执行的流程：
		1. 扩容
			1.  新节点加入集群 (`CLUSTER MEET`)
			2. 批量迁移键值对数据到新节点
			3. 更新集群配置
			4. 平衡节点负载
		2. 缩容
			1. 迁移待移除节点的键值对数据
			2. 通知集群忘记节点
			3. 关闭节点服务
			4. 平衡节点负载
	3. redis的负载均衡：哈希槽分区
		1. redis通过哈希槽分区来实现负载均衡，redis集群在创建的时候，会在每个节点中管理一部分的哈希槽（哈希槽中就是数据）
		2. redis通过哈希算法（redis访问或者存储一个key都会通过哈希算法计算位置）保证key均匀的分布在所有哈希槽中，也可以理解为均匀的分布在不同的redis节点中
		3. 扩容或者缩容时，每个节点管理的哈希槽会重新分配
		4. 优化点：可以进行读写分离，将读操作到从节点上进行（主节点和从节点数据是一样的）；或者手动划分哈希槽
	4. redis的持久化分布
		1. 数据快照（RDB）：通过创建数据集快照（也就是当前的redis中保存的数据集），优点是文件小，并且加载快，缺点是在快照后的数据无法保存
		2. 追加日志文件（AOF）：通过记录redis的每一次写操作，写入操作通过追加写入的方式，实现对redis数据的记录。优点是记录每一次的写入操作，缺点是恢复速度比较慢
		3. 优化方式：两者同时使用，定期备份数据快照，同时追加写入日志，在数据丢失时，通过RDB恢复一部分数据，然后通过重放aof恢复最后一次快照之后的数据（redis4.0版本已经支持）
	5. 分布式调用redis如何保证两次请求不重复
		1.  redis通过哈希槽分区机制来将每一个key映射到唯一的节点中
		2. redis支持事务机制，也有分布式锁，如果由于网络重试或者其他原因导致redis接受了两个相同的请求，redis自己并不会做处理，redis只保证命令顺序执行，不会检测重复请求，如果希望避免这种重复请求，需要客户端自行实现，比如为请求生成一个唯一id或者lua脚本实现等
12. ng的负载均衡，算法具体如何实现，如何保证这个请求到指定的服务中
	1. ng的负载均衡算法
		1. 轮询：计算每一个服务器的权重，选择最大的哪一个
			1. 默认轮询，按顺序分配
			2. 加权轮询：通过参数分配权重
		2. 最少链接：优先分配给当前连接数最少的服务器，ng为每一个服务器维护了一个连接计数器，在分配时根据这个计数器，将连接转发到连接数最少的那个服务器
	2. ng通过域名路由配置或者路径前缀配置，来将对应的请求转发到对应的后台服务中。如果是这个请求是如何从客户端到达后端服务，这就需要dns域名解析，ip路由寻址转发，再到ng的代理（http的流程）
13. mongdb的基本使用，实现原理
	1. mongodb是基于bjson格式存储的文档型数据库，支持嵌套结构，无需预定义表结构，字段可以动态删减，支持通过分片进行水平扩展
	2. 和关系型数据库的区别是：关系型的表在mongdb中是集合，行是文档，列是属性
	3. 默认存储引擎：wiredTiger
14. mq的使用，mq的消息堆积，mq的消息丢失
	1. 使用场景：
		1. 异步处理
		2. 系统解耦
		3. 流量削峰
		4. 分布式事务
	2. 常见问题
		1. 消息堆积
			1. 增加消费者实例
			2. 批量消费消息
			3. 将消息写入死信队列，人工处理
		2. 消息重复
			1. 为消息添加唯一id，处理前检查处理状态
			2. 业务逻辑去重（主键唯一或者业务处理）
		3. 消息丢失
			1. 生产者使用异步回调确认消息+消息重试
			2. 消费者处理完成后手动确认，使用数据库唯一主键以及事务控制
		4. 消息乱序
			1. 使用kafka，相同key的消息会被写入到东一个分区
15. dubbo和zk
	1. 简介
		1. dubbo：dubbo是一块高性能rbc框架，主要用于分布式服务治理，核心功能有服务自动注册、负载均衡、服务容错、服务治理等
		2. zk：分布式协调服务，一般用作注册中心（nacos也可以用作注册中心）
	2. dubbo与zk的协作：
		1. 服务注册：项目启动时，dubbo的provider想zk注册服务地址
		2. 服务发现：consumer从zk订阅服务地址列表，并缓存服务本地
		3. 健康检测：provider和zk保持心跳健康检测，当provider移除了节点或者断连时，zk自动移除节点（zk宕机时，可以使用dubbo本地缓存的服务列表）
	3. dubbo的服务治理以及服务容错是怎么实现的
		1. 服务治理
			1. 服务注册：通过与zk/nacos等注册中心维护
				1. 生产者向zk注册服务地址，消费者向zk获取服务地址，服务中动态生成对应类，进行调用
			2. 负载均衡
				1. 随机
				2. 加权轮询（算法与ng一致）
				3. 最少活跃调用
			3. 限流：dubbo的生产者可以实现限流处理
		2. 服务容错
			1. 熔断降级：dubbo有提供配置，可以设置降级调用的服务接口
			2. 失败重试配置
	4. 除了dubbo和zk，还用过其他相关的类似服务么
		1. 客户端
		2. 网关：shenyu、springcloudGateway
		3. 用户服务集群：dubbo、grpc、springcloud
		4. 注册中心：zookeeper、nacos
		5. 配置中心：apollo、springcloudconfig
		6. 消息队列
		7. 监控体系：skywalking
	5. dubbo的注册机制以及zk的注册机制
		1. dubbo注册：
			1. 生产者通过配置或者注解启用注册，服务启用nety服务监听端口，想注册中心写入服务元数据
			2. 消费者通过配置或注解自动订阅，从注册中心拉去服务列表，根据列表中的服务元数据，生成代理对象，执行方法
	6. 如果一个分布式服务突然关闭，在zk注册中心中对应的数据会删除么，如果会删除，通过什么方式，如果不会，为什么
		1. 正常会话关闭，zk会自动删除对应的注册信息
		2. 服务突然关闭，比如程序崩溃，由于心跳健康检查的存在，并不会及时删除，会等到绘画超时后，才会删除
	7. zk在服务中启用流程是什么样的：直接在应用启用时，配置dubbo的注册中心配置为dubbo的地址即可
	8. zk除了用作服务注册还可以用做什么
		1. 可以用作分布式配置管理（同apollo）
		2. 命名服务：可以用于全局唯一id生成，id严格单调递增，且包含日期信息
			1. 顺序节点：zk在创建节点时添加顺序标识，会自动追加递增序列号（10位十进制数）
			2. 通过原子广播协议保证所有节点的顺序不冲突

17. nacos一般用作什么，apollo呢，两者的实现原理是什么
18. linux下的排查问题过程，cpu占用过高、内存溢出等
	1. cpu占用过高
		1. 进程定位：top命令（查看cpu占用，按p排序），htop命令，mpstat -p ALL 1查看每个cpu核心的使用状况
		2. 线程定位：top -Hp pid，使用ps 查看线程
		3. 分析线程堆栈：

20. top命令中的cpu占用linux系统是如何计算的
21. 有哪些具体的生产调优过程，最后发现问题是什么，如何解决

22. rbac是什么，除了rbac，还了解别的权限管理么，这几种权限管理模型各有什么优缺点，适用场景是什么
23. 登陆注册日志落库流程是什么样的，日志数据为什么是这么生成的，为什么这么做，通过什么避免消息重复以及id重复
24. 对大数据量的数据，进行操作，有什么需要注意的地方，如果需要对这个表操作进行调优，应该怎么做，有哪些常用的sql调优方式，如何进行读写分离
25. 三方平台的标准化插件的开发流程是什么样的，开发完成后执行流程是什么样的，为什么要基于groovy脚本开发插件，如何避免groovy脚本执行非法操作
26. 如何实现三方平台的高并发处理
27. 数据采集平台的作用，为什么要开发这么一个系统，系统的实现原理是什么
28. bi报表为什么要划分pc端以及移动端，如何实现数据权限控制，在bi报表中，缓存优化体现在哪些方面
29. springcloud中的注册中心是哪一个
30. java中的服务治理通过什么