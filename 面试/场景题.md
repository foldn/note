1. 常见防刷策略
	1. 前端添加滑动验证码组件：可以防止前端脚本
	2. 后端进行防刷处理：
		1. IP黑名单/IP白名单：指定某些恶意ip不允许访问，或者针对某些敏感接口仅允许白名单访问
			1. 一般黑名单的处理会和后台限流一起处理，超过恶意频率的访问ip或用户被加入黑名单，指定事件后才能继续访问
		2. 后台接口限流：一般通过后台redis进行用户访问频率进行记录，可以通过redis的zset来实现指定时间内的频率控制,使用zet存储用户id+时间戳，根据时间戳来进行范围判断
	3. 前端一个小技巧，签名时间戳进行修改，第十三位通过前十二位计算得出（防呆瓜），可以避免不读源码直接mock接口的请求
2. 假如有一个下单的接口，你会如何设计，如果中间的某个流程出错，如何实现数据的回滚，保证用户的资金安全
	1. 分布式事务：系统复杂，所以一般不采用
	2. 本地落表+消息队列异步控制流程状态+补偿机制：相关数据落库，其中使用存储商品/订单状态，订单有多个状态（初始化、待执行、执行中、执行成功、执行失败等等），用户发起订单，库表创建订单请求，请求数据落库。后续将订单提交到消息队列中，通过消息队列异步处理订单的后续操作（执行中-执行成功/失败），一般是相关扣款或者库存，执行成功或者失败后，对对应请求进行回调。最后是补偿机制，对于未确认的订单或者异常失败的订单，执行特殊的补偿操作（例如状态未确认或者状态待重试）
		1. 其中订单一定是幂等的，一次只会有一个订单，可以为订单提供给一个分布式的唯一id
			1. 常见算法有：美团的Leaf算法、雪花算法，还有zk的分布式生成服务
		2. 每一个操作再执行之前，应当都判断当前订单状态是否已经被变更
		3. 其中用户订单在初始化到执行完成中这几个流程应当使用同一个事务（避免事务部分成功，在某个流程失败后，其中的每一个流程都应该做对应的事务失败处理），可以通过roketmq实现事务消息，将本地事务和消息发送进行绑定
		4. 注意：上面的流程每一个都会请求数据库，这在高并发的情况下，需要进行优化
			1. 引入缓存，进行数据预热（也就是对于一些固定数据，提前进行缓存）
			2. 数据库读写分离（springboot使用druid很方便）
			3. 数据写入执行批量写，一条sql同时更新多个数据（如果执行失败，就进行事务回滚，等待后续补偿操作）
			4. 使用消息队列异步操作，降低业务处理压力
3. 假如有一个接口，在数据量不大时，一切正常，后续在数据量量级上来了之后，如何优化这个接口超时问题
	1. 问题可能：
		1. 慢sql查询
		2. 处理逻辑有问题，例如多层循环嵌套
		3. 进行较多阻塞型的操作，浪费线程资源在等待
4. 工作中使用redis的场景
5. http网络异常问题如何定位以及解决
6. http连接池
7. cpu占用过高如何定位以及排查
8. 内存占用过高如何定位以及排查
9. 工作中多线程的处理
10. 动态线程池
11. 如何保证缓存和数据的一致性